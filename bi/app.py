#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import io
from glob import glob
from datetime import datetime

import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.io as pio
from typing import Optional, Tuple

APP_TITLE = "é‡‘èâ€œäº”ç¯‡å¤§æ–‡ç« â€å…¬å¼€æ•°æ®ä»ªè¡¨ç›˜"
APP_DESC = (
    "æ¥è‡ªå›½åŠ¡é™¢æœç´¢ï¼ˆåˆ—è¡¨ï¼‰ä¸ä¸–ç•Œé“¶è¡Œå¼€æ”¾APIçš„ç¤ºä¾‹æ€§å¯è§†åŒ–ã€‚"
    "å·¦ä¾§å¯è°ƒæ•´æŒ‡æ ‡ä¸æ—¶é—´èŒƒå›´ï¼›å›¾è¡¨å¯æ‚¬åœæŸ¥çœ‹æ•°å€¼ã€‚"
)

DEFAULT_INDICATORS = [
    "IP.PAT.RESD",       # å±…æ°‘ä¸“åˆ©ç”³è¯·é‡ï¼ˆç§‘æŠ€-åˆ›æ–°æ´»åŠ¨ä»£ç†ï¼‰
    "EN.ATM.CO2E.PC",    # äººå‡äºŒæ°§åŒ–ç¢³æ’æ”¾ï¼ˆç»¿è‰²ï¼‰
    "SP.POP.65UP.TO.ZS", # 65å²åŠä»¥ä¸Šäººå£å æ¯”ï¼ˆå…»è€ï¼‰
    "IT.NET.USER.ZS",    # äº’è”ç½‘ä½¿ç”¨ç‡ï¼ˆæ•°å­—ï¼‰
]

INDICATOR_TOPIC = {
    "IP.PAT.RESD": "ç§‘æŠ€é‡‘è",
    "EN.ATM.CO2E.PC": "ç»¿è‰²é‡‘è",
    "SP.POP.65UP.TO.ZS": "å…»è€é‡‘è",
    "IT.NET.USER.ZS": "æ•°å­—é‡‘è",
}

INDICATOR_DEF = {
    "IP.PAT.RESD": "å±…æ°‘ä¸“åˆ©ç”³è¯·é‡ï¼šæŒ‰ç”³è¯·äººå±…ä½åœ°è®¡é‡çš„ä¸“åˆ©ç”³è¯·ä»¶æ•°ï¼ˆå¹´ï¼‰ã€‚ä¸–ç•Œé“¶è¡Œè½¬è‡ªWIPOå£å¾„ã€‚",
    "EN.ATM.CO2E.PC": "äººå‡äºŒæ°§åŒ–ç¢³æ’æ”¾ï¼šCOâ‚‚æ’æ”¾æ€»é‡/äººå£ï¼ˆå¨/äººï¼Œå¹´ï¼‰ã€‚æ¥æºï¼šä¸–ç•Œé“¶è¡Œç¯å¢ƒæ•°æ®åº“ã€‚",
    "SP.POP.65UP.TO.ZS": "65å²åŠä»¥ä¸Šäººå£å æ¯”ï¼š65+äººå£/æ€»äººå£ï¼ˆ%ï¼‰ã€‚æ¥æºï¼šä¸–ç•Œé“¶è¡Œäººå£æ•°æ®åº“ã€‚",
    "IT.NET.USER.ZS": "äº’è”ç½‘ä½¿ç”¨ç‡ï¼šä½¿ç”¨äº’è”ç½‘çš„äººå£å æ¯”ï¼ˆ%ï¼‰ã€‚æ¥æºï¼šITU/ä¸–ç•Œé“¶è¡Œã€‚",
}

INDICATOR_CN_NAME = {
    "IP.PAT.RESD": "å±…æ°‘ä¸“åˆ©ç”³è¯·é‡",
    "EN.ATM.CO2E.PC": "äººå‡äºŒæ°§åŒ–ç¢³æ’æ”¾",
    "SP.POP.65UP.TO.ZS": "65å²åŠä»¥ä¸Šäººå£å æ¯”",
    "IT.NET.USER.ZS": "äº’è”ç½‘ä½¿ç”¨ç‡",
}

INDICATOR_UNIT = {
    "IP.PAT.RESD": "ä»¶",
    "EN.ATM.CO2E.PC": "å¨/äºº",
    "SP.POP.65UP.TO.ZS": "%",
    "IT.NET.USER.ZS": "%",
}

COLOR_MAP_ID = {
    "IP.PAT.RESD": "#1f77b4",
    "EN.ATM.CO2E.PC": "#2ca02c",
    "SP.POP.65UP.TO.ZS": "#d62728",
    "IT.NET.USER.ZS": "#9467bd",
}


def _find_latest(path_pattern: str) -> Optional[str]:
    files = glob(path_pattern)
    if not files:
        return None
    files.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return files[0]


def _find_from_manifest() -> Tuple[Optional[str], Optional[str], Optional[str]]:
    runs_dir = os.path.join(os.getcwd(), "runs")
    if not os.path.isdir(runs_dir):
        return None, None, None
    manifest = _find_latest(os.path.join(runs_dir, "manifest_*.json"))
    if not manifest:
        return None, None, None
    try:
        with open(manifest, "r", encoding="utf-8") as f:
            m = json.load(f)
        outs = (m.get("outputs") or {})
        return outs.get("worldbank"), outs.get("gov_news"), manifest
    except Exception:
        return None, None, None


def load_worldbank(csv_path: str) -> pd.DataFrame:
    df = pd.read_csv(csv_path)
    # Ensure types
    df["date"] = pd.to_numeric(df["date"], errors="coerce")
    df = df.rename(columns={"date": "year"})
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df = df.dropna(subset=["year"]).copy()
    df["year"] = df["year"].astype(int)
    # Keep CHN only if present
    if "countryiso3code" in df.columns:
        chn = df[df["countryiso3code"] == "CHN"].copy()
        if not chn.empty:
            df = chn
    df["indicator_cn"] = df["indicator_id"].map(INDICATOR_CN_NAME).fillna(df["indicator_id"])
    df["topic"] = df["indicator_id"].map(INDICATOR_TOPIC).fillna("æŒ‡æ ‡")
    df["å•ä½"] = df["indicator_id"].map(INDICATOR_UNIT).fillna("")
    return df


def make_index(df: pd.DataFrame, base_year: int) -> pd.DataFrame:
    # ComputeæŒ‡æ•°(åŸºæœŸ=100)ï¼Œé€æŒ‡æ ‡ç‹¬ç«‹å½’ä¸€
    df = df.copy()
    df.sort_values(["indicator_id", "year"], inplace=True)
    idx_vals = []
    for ind, g in df.groupby("indicator_id"):
        g = g.copy()
        base = g.loc[g["year"] == base_year, "value"]
        base_val = np.nan
        if not base.empty:
            base_val = base.iloc[0]
        g["index"] = np.where(
            pd.notna(base_val) & (base_val != 0), g["value"] / base_val * 100.0, np.nan
        )
        idx_vals.append(g)
    return pd.concat(idx_vals, axis=0, ignore_index=True)


def yoy_change(df: pd.DataFrame) -> pd.DataFrame:
    # é€æŒ‡æ ‡è®¡ç®—åŒæ¯”%
    df = df.sort_values(["indicator_id", "year"]).copy()
    df["yoy_pct"] = df.groupby("indicator_id")["value"].pct_change(fill_method=None) * 100.0
    df["indicator_cn"] = df["indicator_id"].map(INDICATOR_CN_NAME).fillna(df["indicator_id"])
    return df


def load_news(jsonl_path: str) -> pd.DataFrame:
    rows = []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                rows.append(json.loads(line))
            except Exception:
                continue
    if not rows:
        return pd.DataFrame(columns=["pub_date", "title", "url", "snippet"])  
    df = pd.DataFrame(rows)
    # Parse dates
    if "pub_date" in df.columns:
        df["pub_date"] = pd.to_datetime(df["pub_date"], errors="coerce")
    else:
        df["pub_date"] = pd.NaT
    return df


def news_monthly(df_news: pd.DataFrame) -> pd.DataFrame:
    dfn = df_news.copy()
    dfn = dfn.dropna(subset=["pub_date"]) if "pub_date" in dfn.columns else dfn
    if dfn.empty:
        return pd.DataFrame({"month": [], "count": []})
    dfn["month"] = dfn["pub_date"].dt.to_period("M").dt.to_timestamp()
    agg = dfn.groupby("month").size().reset_index(name="count")
    return agg


# ---------------------- Streamlit App ----------------------

st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ“ˆ", layout="wide")
pio.templates.default = "plotly_white"
PLOT_CONFIG = {"locale": "zh-CN", "displaylogo": False}
st.title(APP_TITLE)
st.caption(APP_DESC)

# Load paths (manifest first, then fallbacks)
wb_path, news_path, manifest_path = _find_from_manifest()
wb_fallback = _find_latest(os.path.join("data", "wb", "worldbank_*.csv"))
news_fallback = _find_latest(os.path.join("data", "news", "gov_search_*.jsonl"))
if wb_path is None:
    wb_path = wb_fallback
if news_path is None:
    news_path = news_fallback

with st.sidebar:
    st.header("æ•°æ®é€‰æ‹©")
    if manifest_path:
        st.success(f"å·²åŠ è½½æ¸…å•: {os.path.basename(manifest_path)}")
    else:
        st.info("æœªæ‰¾åˆ°è¿è¡Œæ¸…å•ï¼Œå·²å°è¯•ä½¿ç”¨ data/ ä¸‹æœ€æ–°æ–‡ä»¶")
    wb_path = st.text_input("ä¸–ç•Œé“¶è¡Œ CSV è·¯å¾„", value=wb_path or "")
    news_path = st.text_input("å›½åŠ¡é™¢æœç´¢ JSONL è·¯å¾„", value=news_path or "")

# Guard
if not wb_path or not os.path.exists(wb_path):
    st.warning("æœªæ‰¾åˆ°ä¸–ç•Œé“¶è¡ŒCSVï¼Œè¯·å…ˆè¿è¡Œé‡‡é›†è„šæœ¬ç”Ÿæˆæ•°æ®ã€‚")
    st.stop()

# Load data
wb = load_worldbank(wb_path)
if wb.empty:
    st.warning("ä¸–ç•Œé“¶è¡Œæ•°æ®ä¸ºç©ºã€‚")
    st.stop()

news = None
if news_path and os.path.exists(news_path):
    news = load_news(news_path)

# Sidebar controls
with st.sidebar:
    st.subheader("æŒ‡æ ‡ä¸æ—¶é—´")
    year_min, year_max = int(wb["year"].min()), int(wb["year"].max())
    years = st.slider("å¹´ä»½èŒƒå›´", min_value=year_min, max_value=year_max, value=(max(year_min, year_max-10), year_max))

    all_inds = sorted(wb["indicator_id"].dropna().unique().tolist())
    default_inds = [i for i in DEFAULT_INDICATORS if i in all_inds] or all_inds[:4]
    sel_inds = st.multiselect(
        "é€‰æ‹©æŒ‡æ ‡ï¼ˆæœ€å¤š 4-6 ä¸ªä»¥ä¿è¯å¯è¯»ï¼‰",
        options=all_inds,
        default=default_inds,
        format_func=lambda x: f"{INDICATOR_CN_NAME.get(x, x)}ï¼ˆ{x}ï¼‰",
        help="å°†é¼ æ ‡æ‚¬åœå³ä¾§é—®å·æŸ¥çœ‹æœ¬æ§ä»¶è¯´æ˜ï¼›ä¸‹æ–¹å¯å±•å¼€æŸ¥çœ‹å„æŒ‡æ ‡å®šä¹‰ä¸å£å¾„ã€‚",
    )

    normalize = st.toggle("å½’ä¸€åŒ–ä¸ºæŒ‡æ•°(åŸºæœŸ=100)", value=True, help="æŒ‰æ¯ä¸ªæŒ‡æ ‡çš„åŸºæœŸå€¼å½’ä¸€ï¼Œä¾¿äºè·¨æŒ‡æ ‡å¯¹æ¯”")
    base_year = st.number_input("æŒ‡æ•°åŸºæœŸ(å¹´)", value=years[0], min_value=year_min, max_value=year_max)

    st.subheader("æ–°é—»ç­›é€‰")
    kw = st.text_input("æ–°é—»å…³é”®è¯ç­›é€‰", value="")
    if news is not None and news["pub_date"].notna().any():
        mind, maxd = news["pub_date"].min().date(), news["pub_date"].max().date()
        news_range = st.date_input("æ–°é—»æ—¶é—´çª—", value=(mind, maxd))
    else:
        news_range = None

with st.sidebar:
    pop = st.popover("æŒ‡æ ‡å®šä¹‰ä¸å£å¾„")
    with pop:
        if 'sel_inds' in locals() and sel_inds:
            for ind in sel_inds:
                cn = INDICATOR_CN_NAME.get(ind, ind)
                unit = INDICATOR_UNIT.get(ind, "")
                desc = INDICATOR_DEF.get(ind, "æš‚æ— å®šä¹‰")
                st.markdown(f"**{cn}ï¼ˆ{ind}ï¼‰** Â· å•ä½ï¼š{unit if unit else 'â€”'}\n\n{desc}")
        else:
            st.info("è¯·å…ˆåœ¨ä¸Šæ–¹é€‰æ‹©æŒ‡æ ‡")

# Filter WB data
wb_sel = wb[(wb["indicator_id"].isin(sel_inds)) & (wb["year"].between(years[0], years[1]))].copy()
wb_yoy = yoy_change(wb_sel)

if normalize:
    wb_idx = make_index(wb_sel, base_year)
    y_col = "index"
    y_title = "æŒ‡æ•°(åŸºæœŸ=100)"
else:
    wb_idx = wb_sel.copy()
    y_col = "value"
    y_title = "æ•°å€¼ï¼ˆå•ä½éšæŒ‡æ ‡è€Œå¼‚ï¼Œå»ºè®®ä½¿ç”¨â€œæŒ‡æ•°(åŸºæœŸ=100)â€è¿›è¡Œå¯¹æ¯”ï¼‰"

wb_idx["æŒ‡æ ‡"] = wb_idx["indicator_id"].map(INDICATOR_CN_NAME).fillna(wb_idx["indicator_id"])
wb_yoy["æŒ‡æ ‡"] = wb_yoy["indicator_id"].map(INDICATOR_CN_NAME).fillna(wb_yoy["indicator_id"])
color_map_cn = {wb_idx.loc[wb_idx["indicator_id"]==k, "æŒ‡æ ‡"].iloc[0]: v for k, v in COLOR_MAP_ID.items() if (wb_idx["indicator_id"]==k).any()}
wb_idx["å•ä½"] = wb_idx["indicator_id"].map(INDICATOR_UNIT).fillna("")

# KPI summary
latest_year = int(wb_idx["year"].max())
wb_latest = wb_sel[wb_sel["year"] == latest_year]

kpi_cols = st.columns(4)
for i, ind in enumerate(sel_inds[:4]):
    sub = wb_latest[wb_latest["indicator_id"] == ind]
    v = sub["value"].iloc[0] if not sub.empty else np.nan
    yoy_sub = wb_yoy[(wb_yoy["indicator_id"] == ind) & (wb_yoy["year"] == latest_year)]
    yoyp = yoy_sub["yoy_pct"].iloc[0] if not yoy_sub.empty else np.nan
    topic = INDICATOR_TOPIC.get(ind, "æŒ‡æ ‡")
    cn = INDICATOR_CN_NAME.get(ind, ind)
    unit = INDICATOR_UNIT.get(ind, "")
    if pd.notna(v):
        if unit == "%":
            v_str = f"{v:.2f}%"
        else:
            v_str = f"{v:,.2f}{unit}"
    else:
        v_str = "-"
    with kpi_cols[i % 4]:
        st.metric(label=f"{topic} Â· {cn}ï¼ˆ{latest_year}ï¼‰", value=v_str, delta=(f"{yoyp:+.2f}%" if pd.notna(yoyp) else None), delta_color="normal")

# Chart 1: Trend lines
fig1 = px.line(
    wb_idx,
    x="year",
    y=y_col,
    color="æŒ‡æ ‡",
    color_discrete_map=color_map_cn,
    hover_data={"æŒ‡æ ‡": True, "value": ":,.2f", "year": True},
    markers=True,
)
fig1.update_layout(yaxis_title=y_title, xaxis_title="å¹´ä»½", legend_title="æŒ‡æ ‡", font=dict(family="PingFang SC, Microsoft YaHei, Noto Sans CJK SC, Arial", size=14), margin=dict(t=50, b=40, l=40, r=20))
fig1.update_xaxes(dtick=1)
st.subheader("è¶‹åŠ¿ï¼šæŒ‡æ ‡æ—¶é—´åºåˆ—")
st.plotly_chart(fig1, width="stretch", config=PLOT_CONFIG)

# Chart 2: Latest year comparison (bar)
bar_df = wb_idx[wb_idx["year"] == latest_year].copy()
fig2 = px.bar(bar_df, x="æŒ‡æ ‡", y=y_col, color="æŒ‡æ ‡", text_auto=".2f", color_discrete_map=color_map_cn)
fig2.update_layout(yaxis_title=y_title, xaxis_title="æŒ‡æ ‡", showlegend=False, font=dict(family="PingFang SC, Microsoft YaHei, Noto Sans CJK SC, Arial", size=14), margin=dict(t=40, b=40, l=40, r=20))
st.subheader(f"å¯¹æ¯”ï¼š{latest_year} å¹´æŒ‡æ ‡æ°´å¹³")
st.plotly_chart(fig2, width="stretch", config=PLOT_CONFIG)

# Chart 3: YoY change percentage (bar)
yoy_latest = wb_yoy[wb_yoy["year"] == latest_year].copy()
fig3 = px.bar(yoy_latest, x="æŒ‡æ ‡", y="yoy_pct", color="æŒ‡æ ‡", text_auto=".2f", color_discrete_map=color_map_cn)
fig3.update_layout(yaxis_title="åŒæ¯”å˜åŒ–(%)", xaxis_title="æŒ‡æ ‡", showlegend=False, font=dict(family="PingFang SC, Microsoft YaHei, Noto Sans CJK SC, Arial", size=14), margin=dict(t=40, b=40, l=40, r=20))
fig3.update_yaxes(ticksuffix="%")
st.subheader(f"å˜åŒ–ï¼š{latest_year} å¹´åŒæ¯”(%)")
st.plotly_chart(fig3, width="stretch", config=PLOT_CONFIG)

st.subheader("èˆ†æƒ…ï¼šå›½åŠ¡é™¢æœç´¢æ–°é—»æœˆåº¦é¢‘æ¬¡")
if news is not None and not news.empty and news["pub_date"].notna().any():
    dn = news.copy()
    if kw:
        mask_kw = dn[["title", "snippet"]].fillna("").apply(lambda s: s.str.contains(kw, case=False, regex=False))
        mask = mask_kw.any(axis=1)
        dn = dn[mask]
    if news_range is not None and isinstance(news_range, (list, tuple)) and len(news_range) == 2:
        dn = dn[(dn["pub_date"] >= pd.to_datetime(news_range[0])) & (dn["pub_date"] <= pd.to_datetime(news_range[1]))]
    mn = news_monthly(dn)
    if not mn.empty:
        fig4 = px.line(mn, x="month", y="count", markers=True)
        fig4.update_layout(yaxis_title="æ¡æ•°(ç¯‡)", xaxis_title="æœˆä»½", font=dict(family="PingFang SC, Microsoft YaHei, Noto Sans CJK SC, Arial", size=14), margin=dict(t=40, b=40, l=40, r=20))
        st.plotly_chart(fig4, width="stretch", config=PLOT_CONFIG)
    else:
        st.info("ç­›é€‰æ¡ä»¶ä¸‹æ— æ–°é—»æ•°æ®ã€‚")
else:
    st.info("æœªåŠ è½½æˆ–æ— æ³•è§£ææ–°é—»åˆ—è¡¨æ•°æ®ã€‚")

# Data tables
with st.expander("æŸ¥çœ‹æ•°æ®è¡¨(å¯ä¸‹è½½)"):
    st.write("ä¸–ç•Œé“¶è¡Œæ•°æ®ï¼ˆç­›é€‰åï¼‰ï¼š")
    st.dataframe(wb_sel.sort_values(["indicator_id", "year"]))
    csv_buf = io.StringIO()
    wb_sel.to_csv(csv_buf, index=False)
    st.download_button("ä¸‹è½½ç­›é€‰åçš„ä¸–ç•Œé“¶è¡Œæ•°æ®CSV", data=csv_buf.getvalue(), file_name=f"worldbank_filtered_{latest_year}.csv", mime="text/csv")
    if news is not None and not news.empty:
        st.write("æ–°é—»åˆ—è¡¨ï¼ˆéƒ¨åˆ†é¢„è§ˆï¼‰ï¼š")
        news_preview = news[["pub_date", "title", "url"]].sort_values("pub_date", ascending=False).head(50)
        st.dataframe(
            news_preview,
            column_config={
                "url": st.column_config.LinkColumn("åŸæ–‡é“¾æ¥"),
                "pub_date": st.column_config.DatetimeColumn("å‘å¸ƒæ—¶é—´"),
                "title": st.column_config.TextColumn("æ ‡é¢˜"),
            },
            hide_index=True,
            use_container_width=True,
        )
        news_buf = io.StringIO()
        news.to_csv(news_buf, index=False)
        st.download_button("ä¸‹è½½å…¨éƒ¨æ–°é—»CSV", data=news_buf.getvalue(), file_name="gov_news_all.csv", mime="text/csv")

def load_region_csv(path: str) -> Optional[pd.DataFrame]:
    try:
        df = pd.read_csv(path)
    except Exception:
        return None
    cols = {c.lower(): c for c in df.columns}
    region_col = cols.get("region") or cols.get("province") or cols.get("åœ°åŒº") or cols.get("çœä»½")
    year_col = cols.get("year") or cols.get("å¹´ä»½")
    value_col = cols.get("value") or cols.get("æ•°å€¼")
    if not region_col or not value_col:
        return None
    out = df.rename(columns={region_col: "region", value_col: "value"}).copy()
    if year_col:
        out = out.rename(columns={year_col: "year"})
    else:
        out["year"] = None
    if "indicator_id" not in out.columns and "indicator" in df.columns:
        out = out.rename(columns={"indicator": "indicator_id"})
    return out

with st.sidebar:
    st.subheader("åœ°åŒº/æœºæ„æ•°æ®ï¼ˆå¯é€‰ï¼‰")
    region_csv_path = st.text_input("åœ°åŒºæˆ–æœºæ„CSVè·¯å¾„", value="", help="éœ€åŒ…å«åˆ—ï¼šregion/provinceï¼Œvalueï¼Œå¯é€‰ï¼šyearã€indicator")
    geojson_path = st.text_input("ä¸­å›½GeoJSONè·¯å¾„ï¼ˆå¯é€‰ï¼‰", value="", help="è‹¥æä¾›ï¼Œå°†ç»˜åˆ¶åˆ†çœåœ°å›¾ï¼›è¦æ±‚å±æ€§åŒ…å«çœçº§åç§° name")

reg = None
reg_latest = None
figr = None
figm = None
if region_csv_path:
    reg = load_region_csv(region_csv_path)
    if reg is not None and not reg.empty:
        if reg["year"].notna().any():
            latest_reg_year = reg["year"].dropna().astype(str).max()
            reg_latest = reg[reg["year"].astype(str) == latest_reg_year].copy()
        else:
            reg_latest = reg.copy()
        if "indicator_id" in reg_latest.columns:
            inds_reg = sorted(reg_latest["indicator_id"].dropna().unique().tolist())
            ind_sel = st.multiselect("åœ°åŒºæ•°æ®ï¼šé€‰æ‹©æŒ‡æ ‡", inds_reg, default=inds_reg[:1], key="ind_sel_region")
            reg_plot = reg_latest[reg_latest["indicator_id"].isin(ind_sel)].copy()
            figr = px.bar(reg_plot, x="region", y="value", color="indicator_id", barmode="group", text_auto=".2f")
        else:
            figr = px.bar(reg_latest, x="region", y="value", text_auto=".2f")
        figr.update_layout(xaxis_title="åœ°åŒº/æœºæ„", yaxis_title="æ•°å€¼", font=dict(family="PingFang SC, Microsoft YaHei, Noto Sans CJK SC, Arial", size=14))
        if geojson_path and os.path.exists(geojson_path):
            try:
                import json as _json
                with open(geojson_path, "r", encoding="utf-8") as f:
                    gj = _json.load(f)
                figm = px.choropleth(reg_latest, geojson=gj, featureidkey="properties.name", locations="region", color="value", color_continuous_scale="Blues")
                figm.update_geos(fitbounds="locations", visible=False)
                figm.update_layout(margin=dict(t=0, b=0, l=0, r=0))
            except Exception:
                figm = None

# Footer instructions
st.markdown("""
- æ“ä½œæç¤ºï¼š
  - å·¦ä¾§é€‰æ‹©å¹´ä»½èŒƒå›´ä¸æŒ‡æ ‡ï¼›å¯åˆ‡æ¢æŒ‡æ•°å½’ä¸€åŒ–ä»¥ä¾¿è·¨æŒ‡æ ‡å¯¹æ¯”ã€‚
  - æ‚¬åœæŸ¥çœ‹å…·ä½“æ•°å€¼ï¼›ä¸Šæ–¹æŒ‡æ ‡å¡æ˜¾ç¤ºæœ€è¿‘ä¸€å¹´æ•°å€¼åŠåŒæ¯”ã€‚
  - æ–°é—»æ¨¡å—å¯è¾“å…¥å…³é”®è¯å¹¶é™å®šæ—¶é—´çª—ã€‚
- æ³¨ï¼šä¸åŒæŒ‡æ ‡å•ä½ä¸åŒï¼Œå»ºè®®å¼€å¯â€œæŒ‡æ•°(åŸºæœŸ=100)â€è§‚å¯Ÿç›¸å¯¹å˜åŒ–è¶‹åŠ¿ã€‚
""")
